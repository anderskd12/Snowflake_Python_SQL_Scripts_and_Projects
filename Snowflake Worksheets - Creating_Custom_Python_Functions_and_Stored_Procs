
1. Step 1 - Create a python file with a function defined 

in my example: 
    def add_ka(input_string):
        modified_string = input_string + 'ka'
        return modified_string

2. 
Create or use a stage to place the custom py file.   Upload file there
    @KA_DB.K_ANALYTICS.K_STAGE/add_ka.py


3.  Can run a statement below in a SQL worksheet:
create or replace function add_ka(input_string varchar)
returns variant
language python
runtime_version = '3.8'
handler = 'add_ka.add_ka'
imports = ('@KA_DB.K_ANALYTICS.K_STAGE/add_ka.py')

4.  Using the custom function in a sql statement 
select add_ka('what are your initials: ');
SELECT add_ka(SURFER_NAME), * FROM SURFERS


-- Deploying a custom python worksheet as a SP
select * from surfers
--4 

call add_new_surfers()

select * from surfers
--6 added any new defined in dataset - simplified example


Python worksheet info below - then deployed:

# The Snowpark package is required for Python Worksheets. 
# You can add more packages by selecting them using the Packages control and then importing them.

import snowflake.snowpark as snowpark
from snowflake.snowpark.functions import col
import pandas as pd


def main(session: snowpark.Session): 
    # Your code goes here, inside the "main" handler.
    tableName = 'information_schema.packages'
    dataframe = session.table(tableName).filter(col("language") == 'python')

    ### Create snowflake data frame from SELECT statement #############################
    dataframe_sf = session.sql("select * from SURFERS")
    # Print a sample of the dataframe to standard output.
    dataframe_sf.show()
    #vs pandas --  dataframe.head(3)

    ### for learning - setup PANDAS dataframe within the snowflake worksheet - added reference Import above
    #data = {'SURFER_NAME': ['Python_new', 'Work', 'Sheet'],
    #       'HOME_COUNTRY': ['USA', 'USA', 'USA'],
    #       'STANCE':['goofy','goofy','goofy']}
    data = {'SURFER_NAME': ['Python_new2', 'KELLY A2', 'Sheet'],
           'HOME_COUNTRY': ['USA', 'USA', 'USA'],
           'STANCE':['GOOFY','GOOFY','GOOFY']}
    
    df_pandas = pd.DataFrame(data)
    
    print("df_pandas dataframe type: " , type(df_pandas))
    print("dataframe_sf dataframe type: " ,type(dataframe_sf))

    ##### Show conversion to pandas  ############################## 
    df_pandas2 = dataframe_sf.to_pandas()
    print("df_pandas2 converted type: " ,type(df_pandas2))
    print(df_pandas2.head(2))


    #### Show conversion of pandas back to sf dataframe ###########################
    dataframe_sf2 = session.create_dataframe(df_pandas)
    print("dataframe_sf2 converted type: " ,type(dataframe_sf2))
    # why a table instead of a dataframe?  -->  dataframe_sf2 converted type:  <class 'snowflake.snowpark.table.Table'>

    ### JOIN / UNION ALL two sf dataframes together ################################
    df_consolidated = dataframe_sf.union_all(dataframe_sf2)
    print("consolidated rows: ")
    df_consolidated.show()
    #df_consolidated.write.mode("append").save_as_table("SURFERS")

    print("dataframe_sf rows: ")
    dataframe_sf.show()
    print("dataframe_sf2 rows: ")
    dataframe_sf2.show()
    ### If we want ONLY new records ##############################################
    df_new = dataframe_sf2.except_(dataframe_sf) 
    print('new rows dataframe: ')
    df_new.show()
    
    ### Write dataframe to SURFERS table - now all values are in the table ---- 
    df_new.write.mode("append").save_as_table("SURFERS")
    
    '''
    #    df = session.create_dataframe([("short", 1), ("tall", 10)], schema=["category", "height"])
        df = df.to_pandas()
        #do data manipulation
        #convert pandas dataframe to snowpark dataframe
        dataframe = session.create_dataframe(df)
        return dataframe 
        
    '''
    print(df_pandas.head(5))

    #df_lhs.join(df_rhs, df_lhs.col("key") == df_rhs.col("key")).select(df_lhs["key"].as_("key"), "value1", "value2").show()
    
    # Return value will appear in the Results tab.
    return dataframe_sf

'''
snow_df_spend = session.table('campaign_spend')
snow_df_revenue = session.table('monthly_revenue')
And here are some of the other ways to load data into Snowpark DataFrames.

session.sql("select col1, col2... from tableName")
session.read.options({"field_delimiter": ",", "skip_header": 1}).schema(user_schema).csv("@mystage/testCSV.csv")
session.read.parquet("@stageName/path/to/file")
session.create_dataframe([1,2,3], schema=["col1"])
'''



